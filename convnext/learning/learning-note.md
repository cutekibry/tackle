# ConvNeXt 学习笔记
*原文：[A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545)*

## Abstract 摘要
自从 ViT 被发明并迅速取代 CNN 作为最优秀的图像分类模型，图像识别的黄金时代就开始了。但是，朴素的 ViT 并不能很好地解决所有的 CV 任务，比如对象检测和语义分割等。分层 Transformer（例如 Swin Transformer）重新引入了一些 CNN 先验（priors），使得 Trasnformer 在实践中能够作为一个通用的视觉根基（vision backbone），并在大量的视觉任务上表现优秀。然而，这种复合算法之所以表现优秀，还是因为 Tranformer 固有的优势，而非因为卷积本身的先验假设。在本文中，我们重新审视了设计方式，测试纯粹的 CNN 究竟能达到多高的表现水平。我们将根据 ViT 的设计逐渐改进一个标准 ResNet，并探究影响表现的主要因素。最后，我们提出一个标准 CNN 模型，我们将其称为 ConvNeXt。ConvNeXt 比 Transformer 能拥有更高的准确率和可扩展性，同时也保留了标准 CNN 的简易性和高效性。

## 1. Introduction 导言
2010 年至 2019 年，深度学习领域出现了里程碑式的突破，其主要代表是神经网络的复兴，尤其是 CNN（CNN）。图像识别领域的重点从特征工程走向了（CNN）结构设计。虽然后向传递的 CNN 早在 1989 年就已经出现了，但直到 2012 年我们才挖掘出它用于图像特征学习的强大潜能。AlexNet 的引入和同年的“ImageNet moment”（AlexNet 在 ILSVRC2012 取得了远远超过传统方法的准确率提升，这一事件被称为 ImageNet moment），标志着 CV 领域走向了新时代。自此，CV 领域飞速发展，代表性的 CNN，像 VGGNet、Inceptions、ResNe(X)t、DenseNet、MobileNet、EfficientNet 和 RegNet 分别聚焦于准确率、高效性和可扩展性等多个方面，产生了许多有用的设计准则。

CNN 在 CV 界的主导地位并非偶然：“滑动窗口”策略在处理图像时几乎是默认的标准，尤其是在处理高分辨率图像时。CNN 天生带有的先验假设，使得它们适合处理各种各样的 CV 任务。其中最重要的就是平移不变性，这对对象检测之类的任务作用很大。由于 CNN 共用卷积核，所以也具有高效性。在过去几十年里，标准 CNN 一般用于一些特定的、有限的对象类别，例如数字、人脸、行人等。进入 21 世纪 10 年代，基于区域的检测器（region-based detectors）进一步将 CNN 提升成了视觉识别系统中的基本组件。

与此同时，NLP 的神经网络设计走上了另一条不同的道路。Transformer 替代 RNN 成为了主流的模型基石。尽管 CV 和 NLP 有着不同的任务和需求，二者却在 2020 年合流了——ViT 的引入彻底改变了网络架构。除了初始化时将图像拆分为多个补丁，ViT 并没有引入什么关于图像的先验假设，在原始 Transformer 上做的修改也相当少。受益于大模型和大数据集的帮助，Transformer 能够比标准的 ResNet 表现更优秀，尤其是在图像分类上。然而，CV 并不只有图像分类。过去几十年提出的模型都是基于滑动窗口和卷积的，而没有这些先验假设的 ViT 会在其他任务上面临很多挑战。最大的挑战是 ViT 的全局自注意力结构，它的复杂度和输入大小成二次相关。或许这对 ImageNet 分类任务来说还算可以接受，但若要处理更高分辨率的输入，就会十分棘手了。

分层 Transformer 使用复合算法来解决这个问题。例如，“滑动窗口”策略被再次引入 Transformer，使得它们和 CNN 有着更近似的表现。Swin Transformer 就是这一方向上的里程碑，它第一次表明 Transformer 可以被改进并用于大量的 CV 任务，且达到最优秀的表现。这说明卷积并没有成为时代的眼泪，相反地，它一直都是十分必要的。

从这一点出发，很多人尝试将卷积带回到 Transformer 中。遗憾地，添加卷积总有代价：朴素的滑动窗口自注意力机制计算费用过于昂贵；使用循环移位能提升速度，但又让模型变得过于复杂。讽刺的是，CNN 天然就拥有我们想要的这些特性，表现却劣于 Transformer。

和 CNN 的逐步进化不同，ViT 的进化是阶梯性的。在最近的文献中，CNN 和分层 ViT 有异有同：它们都使用了类似的先验假设，但在模型架构和训练方式上却截然不同。在本文中，我们研究了 CNN 和 Transformer 架构上的不同点，并尝试找出评估模型表现时的干扰因素。我们的研究目的是跨越 ViT 发明前后两个时代，CNN 所应跨越的鸿沟，同时探究朴素 CNN 究竟能达到多高的表现水平。

为此，我们从一个标准 ResNet（例如 ResNet-50）开始。我们将一点点改进，使其变为一个分层 ViT（例如 Swin-T）。这就引出了一个重要问题：究竟是 Transformer 的什么设计，影响了 CNN 的表现？针对这一问题，我们研究并发现了一些影响模型表现的关键因素，并提出一个标准 CNN 模型，我们将其称为 ConvNeXt。令人惊喜的是，ConvNeXt 在所有主流测试上的准确率、可扩展性和泛用性均高于 Transformer，同时保留了 CNN 结构的简易性，使其极其容易实现且高效。

我们希望这一发现能影响过去的某些主流观点，并鼓励人们去重新思考 CV 中卷积的重要性。

## 2. Modernizing a ConvNet: a Roadmap 使一个 CNN 变得现代化：改进过程
本节，我们将说明如何将一个 ResNet 改造为一个类似 Transformer 的 CNN。

我们考虑两对同等 FLOPs 的模型，一对是 ResNet-50 和 Swin-T（FLOPs 约为 $4.5 \times 10^9$），另一对是 ResNet-200 和 Swin-B（FLOPs 约为 $15.0 \times 10^9$）。简单起见，我们仅展示 ResNet-50 和 Swin-T 的结果，更大模型的结构是类似的，可以在附录 C 中找到。

改进过程如下。首先，用类似 ViT 的训练方法训练 ResNet-50，得到比原始的 ResNet-50 优秀许多的结果，将其视为 baseline。接下来，我们研究了一系列的改动，可以总结为：1）宏观层面设计；2）ResNeXt 设计；3）倒转 bottleneck；4）更大的核大小；5）细节层面设计。图 2 展示了调整过程。考虑到模型复杂度和表现水平相关，我们努力控制了调整过程的 FLOPs，避免其发生过大变化。所有模型都在 ImageNet-1K 上训练和评估。

![Fig 2](fig2.png)

### 2.1. Training Techniques 训练方式
除了网络架构，训练方式也会影响最终效果。ViT 不仅引入了新的网络结构，还引入了新的训练方式（例如 AdamW 优化器）。最近的研究表明，现代化的训练方式能相当程度上影响 ResNet-50 的表现，因此我们使用和 DeiT 及 Swin Transformer 相近的现代化训练方法。首先，epoch 数由原来的 $90$ 改为 $300$。接着，我们使用 AdamW 优化器，数据处理则使用 Mixup、Cutmix、RandAugment、Random Erasing、Stochastic Depth 和 Label Smoothing。超参数的具体的值可以在附录 A.1 找到。这一改进让准确率从 $76.1\%$ 提升到了 $78.8\%$，说明传统 CNN 和 ViT 的表现区别有可能是因为训练方式不同产生的。

### 2.2. Macro Design 宏观层面设计
接下来，我们分析 Swin Transformer 在宏观层面上的设计。Swin Transformer 和 CNN 一样使用了多阶段设计（multi-stage design），每一阶段图像分辨率都不同。有两点是值得注意的：一是每个阶段 bottleneck 的个数，二是预处理时降采样的方式。

**调整阶段 bottleneck 的个数**。Swin-T 使用的阶段 bottleneck 个数比为 $1:1:3:1$，更大一点的 Swin Transformer 则为 $1:1:9:1$。据此，我们将 ResNet-50 每个阶段的块个数从 $(3, 4, 6, 3)$ 调整为 $(3, 3, 9, 3)$。这使得模型准确率从 $78.8\%$ 提升到了 $79.4\%$，同时 FLOPs 也和 Swin-T 相等。值得一提的是，有人针对这一比例进行了研究，也可能存在比这更好的设计。

**将卷积改为补丁**。由于图像本身具有冗余的信息，所以 CNN 和 ViT 都会在一开始对图像进行激进的降采样处理。CNN 中的实现方式是一个核大小为 $7 \times 7$、步长为 $2$ 的卷积层，加上一个最大池化层，使得图像分辨率变为原来的 $\frac 14$。ViT 的实现方式则更为激进：ViT 将图像转为多个补丁，等价于核大小较大（例如 $14 \times 14$ 或 $16 \times 16$）且不重叠的卷积。Swin Transformer 和后者类似，但使用的核大小仅为 $4 \times 4$，使其适应模型的多阶段设计。我们将 ResNet 的这一卷积层改为一个核大小为 $4 \times 4$、步长为 $4$ 的卷积层，这和 Swim Transformer 的补丁化本质一致。这将准确率从 $79.4\%$ 提升到了 $79.5\%$。

### 2.3. ResNeXt-ify ResNeXt 化
在本节，我们考虑使用 ResNeXt 的改进思路，使得我们能以较少的 FLOPs 增大带来较大的准确率提升。ResNeXt 的一个重要改进就是分组卷积：将 bottleneck 的 $3 \times 3$ 卷积层改为组卷积，同时增大网络宽度以弥补改动带来的容量损失。

这里，我们使用分离卷积（depthwise convolution），一种特殊的分组卷积：每个输入通道唯一对应一个输出通道和一组卷积核参数，输入通道数等于输出通道数。分离卷积已在 MobileNet 和 Xception 中被使用，并推广到其他模型中。值得注意的是，使用一层分离卷积和一层 $1 \times 1$ 卷积可以先后（而不是同时）实现空间维度的处理和不同通道信息之间的混合，这和 ViT 是异曲同工的。参照 ResNeXt 的处理方法，我们在使用分离卷积的同时将通道数从